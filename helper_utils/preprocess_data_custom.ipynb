{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81145069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nam/miniconda3/envs/diff/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds_train = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0007c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chosen': [{'content': 'Use the pygame library to write a version of the classic game Snake, with a unique twist',\n",
       "   'role': 'user'},\n",
       "  {'content': \"Sure, I'd be happy to help you write a version of the classic game Snake using the pygame library! Here's a basic outline of how we can approach this:\\n\\n1. First, we'll need to set up the game display and create a game object that we can use to handle the game's state.\\n2. Next, we'll create the game's grid, which will be used to represent the game board. We'll need to define the size of the grid and the spaces within it.\\n3. After that, we'll create the snake object, which will be used to represent the player's movement. We'll need to define the size of the snake and the speed at which it moves.\\n4. We'll also need to create a food object, which will be used to represent the food that the player must collect to score points. We'll need to define the location of the food and the speed at which it moves.\\n5. Once we have these objects set up, we can start handling the game's logic. We'll need to define the rules for the player's movements, such as how the player can move the snake and how the snake will grow as the player collects more food.\\n6. We'll also need to add collisions detection to the game, so that the snake and the food can collide with each other.\\n7. Finally, we'll need to add a user interface to the game, such as a menu and a scoreboard.\\n\\nNow, as for the unique twist, we could add a few features to make the game more interesting. For example, we could add power-ups that give the player special abilities, such as the ability to grow the snake faster or to change its direction. We could also add obstacles, such as walls or pits, that the player must avoid.\\n\\nHere's some sample code to get us started:\\n```\\nimport pygame\\n\\n# Initialize pygame\\npygame.init()\\n\\n# Set up the game display\\nwidth = 800\\nheight = 600\\nscreen = pygame.display.set_mode((width, height))\\n\\n# Define the colors\\nWHITE = (255, 255, 255)\\nBLACK = (0, 0, 0)\\nGREEN = (0, 255, 0)\\n\\n# Define the game objects\\nsnake = pygame.Rect(50, 50, 10, 10)\\nfood = pygame.Rect(100, 100, 10, 10)\\n\\n# Define the game logic\\ndef update_snake():\\n    # Get the mouse position\\n    mouse_pos = pygame.mouse.get_pos()\\n\\n    # Move the snake based on the mouse position\\n    if mouse_pos[0] > snake.x:\\n        snake.x += 10\\n    elif mouse_pos[0] < snake.x:\\n        snake.x -= 10\\n    elif mouse_pos[1] > snake.y:\\n        snake.y += 10\\n    elif mouse_pos[1] < snake.y:\\n        snake.y -= 10\\n\\n    # Update the snake's size\\n    if snake.x == food.x and snake.y == food.y:\\n        snake.width += 10\\n        snake.height += 10\\n\\n# Define the game loop\\ndef game_loop():\\n    # Clear the screen\\n    screen.fill(BLACK)\\n\\n    # Update the game objects\\n    update_snake()\\n\\n    # Draw the game objects\\n    screen.fill(WHITE)\\n    screen.draw.rect(snake, GREEN)\\n    screen.draw.rect(food, BLACK)\\n\\n    # Update the display\\n    pygame.display.flip()\\n\\n# Start the game loop\\ngame_loop()\\n\\n# Run the game\\nwhile True:\\n    for event in pygame.event.get():\\n        if event.type == pygame.QUIT:\\n            pygame.quit()\\n            break\\n\\n    pygame.time.Clock().tick(60)\\n```\\nThis code sets up a basic game display, defines the snake and food objects, and updates the game state based on the player's movements. We've also added a simple user interface and some basic collision detection.\\n\\nAs for the unique twist, we could add a few features to make the game\",\n",
       "   'role': 'assistant'}],\n",
       " 'rejected': [{'content': 'Use the pygame library to write a version of the classic game Snake, with a unique twist',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Sure, here\\'s an example of how to write a version of Snake game with a unique twist using the Pygame library:\\n```python\\nimport pygame\\n\\nclass SnakeGame:\\n    def __init__(self, game_width, game_height):\\n        pygame.init()\\n        screen = pygame.display.set_mode((game_width, game_height))\\n        pygame.display.set_caption(\"Snake Game\")\\n        self.speed = 5  # Speed of the snake\\n        self.food_speed = 1  # Speed of the food\\n        self.direction = 0  # Initial direction of the snake\\n        self.snakelen = 0  # Length of the snake\\n        self.food = pygame.image.load(\"snake_food.png\")\\n        self.head = pygame.image.load(\"snake_head.png\")\\n        self.tail = pygame.image.load(\"snake_tail.png\")\\n        self.game Quint()\\n    def Quint(self):\\n        for i in range(50):\\n            pygame.draw.line(screen, (180, 100, 220), (0, 0, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 0, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 50, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 50, 300), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 80, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 80, 300), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 50, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 50, 300), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 80, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 80, 300), 2)\\n            pygame.display.flip()\\n        self.game.run()\\n    def run(self):\\n        while True:\\n            for event in pygame.event. pygame.KEYDOWN:\\n                if event.key == pygame.K_LEFT:\\n                    self.direction = -1\\n                if event.key == pygame.K_RIGHT:\\n                    self.direction = 1\\n            self.snakelen += 1\\n            if self.snakelen == 0:\\n                self.snakelen = 10\\n            if self.snakelen > 20:\\n                self.snakelen = 20\\n            self.gameQuint()\\n            self.foodCrossing()\\n            self.headRun()\\n            pygame.display.update()\\ngame = SnakeGame(800, 600)\\ngame.run()\\n```\\nIn this game, the snake moves with a constant speed, but the direction of the snake can be controlled by the user using the left and right arrow keys. The snake grows in length every 10 segments, and when it reaches a certain length, it resets to 10 segments. The food moves fast and randomly crosses the screen, and the snake can eat it by colliding with it. The snake\\'s head and tail move independently of each other. The game ends when the snake dies or reaches the end of the screen.',\n",
       "   'role': 'assistant'}],\n",
       " 'score_chosen': 6.0,\n",
       " 'score_rejected': 4.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f47138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nam/miniconda3/envs/diff/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal</th>\n",
       "      <th>gen_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm really tired today, I think I need some rest.</td>\n",
       "      <td>I'm totally drained today, need to catch some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm really tired today, I just want to relax a...</td>\n",
       "      <td>I'm hella drained today, just wanna chill at h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm really excited for the concert tonight.</td>\n",
       "      <td>I'm so hype for the concert tonight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm really tired today, I think I need some co...</td>\n",
       "      <td>I'm so drained today, I gotta get me some caff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm really looking forward to the weekend.</td>\n",
       "      <td>I'm so hyped for the weekend, can't wait to tu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              normal  \\\n",
       "0  I'm really tired today, I think I need some rest.   \n",
       "1  I'm really tired today, I just want to relax a...   \n",
       "2        I'm really excited for the concert tonight.   \n",
       "3  I'm really tired today, I think I need some co...   \n",
       "4         I'm really looking forward to the weekend.   \n",
       "\n",
       "                                               gen_z  \n",
       "0  I'm totally drained today, need to catch some ...  \n",
       "1  I'm hella drained today, just wanna chill at h...  \n",
       "2               I'm so hype for the concert tonight.  \n",
       "3  I'm so drained today, I gotta get me some caff...  \n",
       "4  I'm so hyped for the weekend, can't wait to tu...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/Programmer-RD-AI/genz-slang-pairs-1k/genz_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa077588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nam/miniconda3/envs/diff/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 41 files: 100%|██████████| 41/41 [00:00<00:00, 92604.45it/s]\n",
      "Fetching 41 files: 100%|██████████| 41/41 [00:00<00:00, 101395.32it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(200020, 2880, padding_idx=199999)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"openai/gpt-oss-20b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "#  This takes up around 13GB VRAM\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': ['<CUSTOM>']})\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b7565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_gpt_prompt_from_template(normal_sentence):\n",
    "    gpt_prompt_template_for_genz = f\"<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI. You must answer in 1 sentence and only what you are asked. DO NOT overanalyse this query. Assume whatever you want. You MUST answer with something ALWAYS.<|end|><|start|>user<|message|>How do you say '{normal_sentence}' in <CUSTOM> slang?<|end|>\"\n",
    "    return {'content': gpt_prompt_template_for_genz, 'role': 'user'}\n",
    "\n",
    "def post_process_normal_gpt_response(gpt_response, genz_version):\n",
    "    start_pattern_pure_output = \"<|start|>assistant<|channel|>final<|message|>\"\n",
    "    end_pattern_pure_output = \"<|return|>\"\n",
    "    pure_output = None\n",
    "    if len(gpt_response.split(\"<|end|>\")) != 2:\n",
    "        print(\"This sample funny\")\n",
    "        print(gpt_response)\n",
    "    analysis_tokens, output_tokens = gpt_response.split(\"<|end|>\")\n",
    "    pattern = re.escape(start_pattern_pure_output) + r\"(.*?)\" + re.escape(end_pattern_pure_output)\n",
    "    match = re.search(pattern, output_tokens)\n",
    "    if match:\n",
    "        pure_output = match.group(1)\n",
    "        # print(f\"pure_output = {pure_output}\")\n",
    "        # print(\"match found\")\n",
    "        output_tokens = output_tokens.replace(pure_output, genz_version)\n",
    "        if pure_output in analysis_tokens:\n",
    "            # print(\"pure output is in analysis tokens\")\n",
    "            analysis_tokens = analysis_tokens.replace(pure_output, genz_version)\n",
    "\n",
    "    return {'content': analysis_tokens + \"<|end|>\" + output_tokens, 'role': 'assistant'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf22717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1005 [00:53<4:55:52, 17.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sample funny\n",
      "<|start|>...<|end|><|start|>assistant<|channel|>analysis<|message|>The user says: \"How do you say 'I'm really excited for the concert tonight.' in <CUSTOM> slang?\" There's some <CUSTOM> tag. It's presumably something like a placeholder: a custom slang might maybe be \"OMG I'm so hyped!!!\" But it's ambiguous. The user may want the phrase in slanguage for an unknown slang. There's no defined slang provided. The user says \"in <CUSTOM> slang\". Possibly they want something like \"I'm super psyched for the show tonight.\" But the tag <CUSTOM> perhaps indicates they want me to make up an inventive slang. But the instruction says: \"You are ChatGPT... You must answer in 1 sentence and only what you are asked. You MUST answer ... Assume whatever you want.\" So I can assume \"CUSTOM\" is some slang. Let's produce a creative slang: \"Yo, I'm lit AF for the concert tonight!\" This is 1 sentence, that covers. There's no requirement to explain or anything else.<|end|><|start|>assistant<|channel|>final<|message|>Yo, I’m stoked to crash the show tonight!<|return|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1005 [01:37<6:46:48, 24.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m ip_for_gpt \u001b[38;5;241m=\u001b[39m generate_gpt_prompt_from_template(normal)\n\u001b[1;32m     10\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(ip_for_gpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 11\u001b[0m generated \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m700\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# pprint(tokenizer.decode(generated[0][inputs[\"input_ids\"].shape[-1] :]))\u001b[39;00m\n\u001b[1;32m     13\u001b[0m op_from_default_gpt \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: tokenizer\u001b[38;5;241m.\u001b[39mdecode(generated[\u001b[38;5;241m0\u001b[39m][inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] :]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/transformers/generation/utils.py:2668\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[1;32m   2667\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[0;32m-> 2668\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2669\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2670\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2674\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/transformers/generation/utils.py:2873\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2871\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2872\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_model_for_decode():\n\u001b[0;32m-> 2873\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2874\u001b[0m prefill_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2875\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   2876\u001b[0m     outputs,\n\u001b[1;32m   2877\u001b[0m     model_kwargs,\n\u001b[1;32m   2878\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2879\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/transformers/utils/generic.py:841\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    840\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[0;32m--> 841\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    843\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py:660\u001b[0m, in \u001b[0;36mGptOssForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_router_logits, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m output_router_logits \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    656\u001b[0m     output_router_logits \u001b[38;5;28;01mif\u001b[39;00m output_router_logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_router_logits\n\u001b[1;32m    657\u001b[0m )\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 660\u001b[0m outputs: MoeModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_router_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_router_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/transformers/utils/generic.py:915\u001b[0m, in \u001b[0;36mmerge_with_config_defaults.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m             output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;66;03m# Restore original config value\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_causal \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/transformers/utils/output_capturing.py:253\u001b[0m, in \u001b[0;36mcapture_outputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# Run the forward\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# Reset the states\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     _active_collector\u001b[38;5;241m.\u001b[39mreset(output_token)\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py:499\u001b[0m, in \u001b[0;36mGptOssModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(hidden_states, position_ids)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 499\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(hidden_states)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MoeModelOutputWithPast(\n\u001b[1;32m    511\u001b[0m     last_hidden_state\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    512\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    513\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/transformers/modeling_layers.py:93\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py:374\u001b[0m, in \u001b[0;36mGptOssDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m hidden_states, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py:346\u001b[0m, in \u001b[0;36mGptOssAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m attention_interface(\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    334\u001b[0m     query_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    343\u001b[0m )\n\u001b[1;32m    345\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m--> 346\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_proj\u001b[49m(attn_output)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights\n",
      "File \u001b[0;32m~/miniconda3/envs/diff/lib/python3.10/site-packages/torch/nn/modules/module.py:1958\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_buffers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1957\u001b[0m     _buffers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_buffers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 1958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _buffers:\n\u001b[1;32m   1959\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _buffers[name]\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_modules\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "custom_training_data = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    skip_counter, skip_indexes = 0, \n",
    "    row = df.iloc[i]\n",
    "    normal, genz = row[\"normal\"], row[\"gen_z\"]\n",
    "    ip_for_gpt = generate_gpt_prompt_from_template(normal)\n",
    "    inputs = tokenizer(ip_for_gpt['content'], return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    generated = model.generate(**inputs, max_new_tokens=700)\n",
    "    # pprint(tokenizer.decode(generated[0][inputs[\"input_ids\"].shape[-1] :]))\n",
    "    op_from_default_gpt = {'content': tokenizer.decode(generated[0][inputs[\"input_ids\"].shape[-1] :]), 'role': 'assistant'}\n",
    "    try:\n",
    "        post_process_op = post_process_normal_gpt_response(op_from_default_gpt['content'], genz)\n",
    "        # pprint(post_process_op)\n",
    "        row_to_append = {'chosen': [ip_for_gpt, post_process_op],\n",
    "                        'rejected': [ip_for_gpt, op_from_default_gpt],\n",
    "                        'score_chosen': round(random.randint(7, 9)+ random.random(), 2),\n",
    "                        'score_rejected': round(random.randint(1, 4) + random.random(), 2)\n",
    "                        }\n",
    "        # pprint(row_to_append)\n",
    "        custom_training_data.append(row_to_append)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "custom_data_hf_format_df = pd.DataFrame(custom_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2236757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nam/miniconda3/envs/diff/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 42 files: 100%|██████████| 42/42 [00:00<00:00, 106505.91it/s]\n",
      "Loading weights: 100%|██████████| 411/411 [00:02<00:00, 145.56it/s, Materializing param=model.norm.weight]                              \n",
      "100%|██████████| 10/10 [01:03<00:00,  6.35s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/Programmer-RD-AI/genz-slang-pairs-1k/genz_dataset.csv\")\n",
    "model_name = \"openai/gpt-oss-20b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': ['<CUSTOM>']})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "#  This takes up around 13GB VRAM\n",
    "\n",
    "def generate_gpt_prompt_from_template(normal_sentence):\n",
    "    gpt_prompt_template_for_genz = f\"<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI. You must answer in 1 sentence and only what you are asked. DO NOT overanalyse the query. Assume whatever you want. You MUST answer with something ALWAYS. Reasoning: low<|end|><|start|>user<|message|>How do you say '{normal_sentence}' in <CUSTOM> slang?<|end|>\"\n",
    "    return {'content': gpt_prompt_template_for_genz, 'role': 'user'}\n",
    "\n",
    "def post_process_normal_gpt_response(gpt_response, genz_version):\n",
    "    start_pattern_pure_output = \"<|start|>assistant<|channel|>final<|message|>\"\n",
    "    end_pattern_pure_output = \"<|return|>\"\n",
    "    pure_output = None\n",
    "    if len(gpt_response.split(\"<|end|>\")) != 2:\n",
    "        if \"<|start|>???<|end|>\" in gpt_response:\n",
    "            print(\"Funny Sample -> That weird <|start|>???<|end|> pattern\")\n",
    "        elif len(gpt_response.split(\"<|end|>\")) == 1:\n",
    "            print(\"Did not finish thinking\")\n",
    "        else:\n",
    "            print(f\"This sample funny, splits into list of length {len(gpt_response.split('<|end|>'))}\")\n",
    "            print(gpt_response)\n",
    "    analysis_tokens, output_tokens = gpt_response.split(\"<|end|>\")\n",
    "    pattern = re.escape(start_pattern_pure_output) + r\"(.*?)\" + re.escape(end_pattern_pure_output)\n",
    "    match = re.search(pattern, output_tokens)\n",
    "    if match:\n",
    "        pure_output = match.group(1)\n",
    "        # print(f\"pure_output = {pure_output}\")\n",
    "        # print(\"match found\")\n",
    "        output_tokens = output_tokens.replace(pure_output, genz_version)\n",
    "        if pure_output in analysis_tokens:\n",
    "            # print(\"pure output is in analysis tokens\")\n",
    "            analysis_tokens = analysis_tokens.replace(pure_output, genz_version)\n",
    "\n",
    "    return {'content': analysis_tokens + \"<|end|>\" + output_tokens, 'role': 'assistant'}\n",
    "\n",
    "\n",
    "\n",
    "custom_training_data = []\n",
    "for i in tqdm(range(10)):\n",
    "    row = df.iloc[i]\n",
    "    skip_counter, skip_indexes = 0, []\n",
    "    normal, genz = row[\"normal\"], row[\"gen_z\"]\n",
    "    ip_for_gpt = generate_gpt_prompt_from_template(normal)\n",
    "    inputs = tokenizer(ip_for_gpt['content'], return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    generated = model.generate(**inputs, max_new_tokens=700)\n",
    "    # pprint(tokenizer.decode(generated[0][inputs[\"input_ids\"].shape[-1] :]))\n",
    "    op_from_default_gpt = {'content': tokenizer.decode(generated[0][inputs[\"input_ids\"].shape[-1] :]), 'role': 'assistant'}\n",
    "    try:\n",
    "        post_process_op = post_process_normal_gpt_response(op_from_default_gpt['content'], genz)\n",
    "        # pprint(post_process_op)\n",
    "        row_to_append = {'chosen': [ip_for_gpt, post_process_op],\n",
    "                        'rejected': [ip_for_gpt, op_from_default_gpt],\n",
    "                        'score_chosen': round(random.randint(7, 9)+ random.random(), 2),\n",
    "                        'score_rejected': round(random.randint(1, 2) + random.random(), 2)\n",
    "                        }\n",
    "        # pprint(row_to_append)\n",
    "        custom_training_data.append(row_to_append)\n",
    "    except:\n",
    "        skip_counter += 1\n",
    "        skip_indexes.append(i)\n",
    "        pass\n",
    "\n",
    "custom_data_hf_format_df = pd.DataFrame(custom_training_data)\n",
    "\n",
    "custom_data_hf_format_df.to_csv(\"../datasets/mini_custom_genz_dataset_in_hf_format.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b67a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_data_hf_format_df = pd.DataFrame(custom_training_data)\n",
    "\n",
    "custom_data_hf_format_df.to_csv(\"datasets/custom_genz_dataset_in_hf_format.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0dc005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start|>assistant<|channel|>analysis<|message|>We need to transform a sentence into GenZ slang. The user asks: \"How do you say 'I'm really tired today, I think I need some rest.' in GenZ slang?\" They want an answer. Provide a GenZ slang version. \"I'm feeling wiped out today, need some chill vibes.\" Something like that. Perhaps \"I'm straight up beat today, need some chill.\" Should be one sentence. The assistant should answer: \"Low key fried today, gotta catch some z's.\" Or \"I'm shook, totally wiped, need some rest.\" Must be in GenZ slang. Use words like \"woke\" and \"lit\"? The best answer: \"Low-key fried today, need to get some Z's.\" Let's produce that.<|end|><|start|>assistant<|channel|>final<|message|>Low‑key fried today—gonna catch some Zs and recharge.<|return|>\n"
     ]
    }
   ],
   "source": [
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful agent.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"What is the weather like in Madrid?\"},\n",
    "# ]\n",
    "# inputs = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     # add_generation_prompt=True,\n",
    "#     return_tensors=\"pt\",\n",
    "#     return_dict=True,\n",
    "# ).to(model.device)\n",
    "# print(tokenizer.decode(generated[0][inputs[\"input_ids\"].shape[-1] :]).split(\"<|end|><|start|>assistant<|channel|>final<|message|>\")[-1]\n",
    "\n",
    "# prompt = \"<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\" \\\n",
    "# \"\\nKnowledge cutoff: 2024-06\\nCurrent date: 2026-02-27\\n\\nReasoning: medium\\n\\n# \" \\\n",
    "# \"Valid channels: analysis, commentary, final. Channel must be included for every message.\" \\\n",
    "# \"<|end|><|start|>user<|message|> Say 'I'm really tired today, I think I need some rest.' in GenZ slang.<|end|>\"\n",
    "\n",
    "# prompt = \"<|end|><|start|>user<|message|> Say 'I'm really tired today, I think I need some rest.' in GenZ slang.<|end|>\"\n",
    "prompt = \"<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI. Answer in 1 sentence and only what you are asked.<|end|><|start|>user<|message|>How do you say 'I'm really tired today, I think I need some rest.' in GenZ slang?<|end|>\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "\n",
    "generated = model.generate(**inputs, max_new_tokens=700)\n",
    "print(tokenizer.decode(generated[0][inputs[\"input_ids\"].shape[-1] :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87c3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e535fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca87e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "data = {\n",
    "    \"pokemon\": [\"bulbasaur\", \"squirtle\", \"charmander\"],\n",
    "    \"type\": [\"grass\", \"water\", \"fire\"],\n",
    "    \"hp\": [45, 44, 39]\n",
    "}\n",
    "\n",
    "hf_dataset = Dataset.from_dict(data)\n",
    "\n",
    "print(hf_dataset)\n",
    "print(hf_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import DPOTrainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    train_dataset=load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\"),\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
